{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtuomMerkulov/ArtuomMerkulov/blob/main/%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%82%D0%BE%D1%80_%D1%86%D0%B8%D1%82%D0%B0%D1%82_%D0%B4%D1%80%D0%B5%D0%B2%D0%BD%D0%B5%D0%B3%D1%80%D0%B5%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D1%84%D0%B8%D0%BB%D0%BE%D1%81%D0%BE%D1%84%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "kCd0-vwbHM1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7wfSnS5jHXt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/Numpy/philosophy_dataset.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "hH4vwrbDHTlz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "print(char_to_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neTrwW8fIYIB",
        "outputId": "9adeae5a-1bf1-487e-ffb3-43096eb691c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, '\\x0c': 1, ' ': 2, '!': 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'c': 12, '«': 13, '»': 14, 'а': 15, 'б': 16, 'в': 17, 'г': 18, 'д': 19, 'е': 20, 'ж': 21, 'з': 22, 'и': 23, 'й': 24, 'к': 25, 'л': 26, 'м': 27, 'н': 28, 'о': 29, 'п': 30, 'р': 31, 'с': 32, 'т': 33, 'у': 34, 'ф': 35, 'х': 36, 'ц': 37, 'ч': 38, 'ш': 39, 'щ': 40, 'ъ': 41, 'ы': 42, 'ь': 43, 'э': 44, 'ю': 45, 'я': 46, 'ё': 47, '–': 48, '—': 49, '…': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS1m0RIsI-iU",
        "outputId": "015463d1-3bdf-4a9e-b70f-fd6193b32226"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  21016\n",
            "Total Vocab:  51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 1000\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwD7AsOfJYk-",
        "outputId": "3d059e5e-b9c6-4630-9178-bb1bd62da143"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  20016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "id": "pC7Mhl4iJoNX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(256))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "cRIs8nk1Jy1Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "yibzp39qKO0f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=70, batch_size=256, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xlfACRTKQ5C",
        "outputId": "b583aaa1-603a-47d1-d16f-1d903226dfb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.3034\n",
            "Epoch 1: loss improved from inf to 3.30339, saving model to weights-improvement-01-3.3034.hdf5\n",
            "79/79 [==============================] - 50s 549ms/step - loss: 3.3034\n",
            "Epoch 2/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.2212\n",
            "Epoch 2: loss improved from 3.30339 to 3.22119, saving model to weights-improvement-02-3.2212.hdf5\n",
            "79/79 [==============================] - 44s 557ms/step - loss: 3.2212\n",
            "Epoch 3/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.2137\n",
            "Epoch 3: loss improved from 3.22119 to 3.21372, saving model to weights-improvement-03-3.2137.hdf5\n",
            "79/79 [==============================] - 43s 547ms/step - loss: 3.2137\n",
            "Epoch 4/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.2113\n",
            "Epoch 4: loss improved from 3.21372 to 3.21126, saving model to weights-improvement-04-3.2113.hdf5\n",
            "79/79 [==============================] - 44s 551ms/step - loss: 3.2113\n",
            "Epoch 5/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.2066\n",
            "Epoch 5: loss improved from 3.21126 to 3.20665, saving model to weights-improvement-05-3.2066.hdf5\n",
            "79/79 [==============================] - 43s 549ms/step - loss: 3.2066\n",
            "Epoch 6/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.2022\n",
            "Epoch 6: loss improved from 3.20665 to 3.20224, saving model to weights-improvement-06-3.2022.hdf5\n",
            "79/79 [==============================] - 43s 550ms/step - loss: 3.2022\n",
            "Epoch 7/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.1915\n",
            "Epoch 7: loss improved from 3.20224 to 3.19152, saving model to weights-improvement-07-3.1915.hdf5\n",
            "79/79 [==============================] - 44s 554ms/step - loss: 3.1915\n",
            "Epoch 8/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.1693\n",
            "Epoch 8: loss improved from 3.19152 to 3.16925, saving model to weights-improvement-08-3.1693.hdf5\n",
            "79/79 [==============================] - 44s 553ms/step - loss: 3.1693\n",
            "Epoch 9/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.1319\n",
            "Epoch 9: loss improved from 3.16925 to 3.13192, saving model to weights-improvement-09-3.1319.hdf5\n",
            "79/79 [==============================] - 44s 555ms/step - loss: 3.1319\n",
            "Epoch 10/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.1022\n",
            "Epoch 10: loss improved from 3.13192 to 3.10216, saving model to weights-improvement-10-3.1022.hdf5\n",
            "79/79 [==============================] - 44s 554ms/step - loss: 3.1022\n",
            "Epoch 11/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0786\n",
            "Epoch 11: loss improved from 3.10216 to 3.07856, saving model to weights-improvement-11-3.0786.hdf5\n",
            "79/79 [==============================] - 44s 555ms/step - loss: 3.0786\n",
            "Epoch 12/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0597\n",
            "Epoch 12: loss improved from 3.07856 to 3.05973, saving model to weights-improvement-12-3.0597.hdf5\n",
            "79/79 [==============================] - 44s 562ms/step - loss: 3.0597\n",
            "Epoch 13/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0459\n",
            "Epoch 13: loss improved from 3.05973 to 3.04587, saving model to weights-improvement-13-3.0459.hdf5\n",
            "79/79 [==============================] - 44s 563ms/step - loss: 3.0459\n",
            "Epoch 14/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0343\n",
            "Epoch 14: loss improved from 3.04587 to 3.03434, saving model to weights-improvement-14-3.0343.hdf5\n",
            "79/79 [==============================] - 44s 560ms/step - loss: 3.0343\n",
            "Epoch 15/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0188\n",
            "Epoch 15: loss improved from 3.03434 to 3.01881, saving model to weights-improvement-15-3.0188.hdf5\n",
            "79/79 [==============================] - 44s 560ms/step - loss: 3.0188\n",
            "Epoch 16/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.0046\n",
            "Epoch 16: loss improved from 3.01881 to 3.00465, saving model to weights-improvement-16-3.0046.hdf5\n",
            "79/79 [==============================] - 44s 560ms/step - loss: 3.0046\n",
            "Epoch 17/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9945\n",
            "Epoch 17: loss improved from 3.00465 to 2.99446, saving model to weights-improvement-17-2.9945.hdf5\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 2.9945\n",
            "Epoch 18/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9808\n",
            "Epoch 18: loss improved from 2.99446 to 2.98077, saving model to weights-improvement-18-2.9808.hdf5\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 2.9808\n",
            "Epoch 19/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9654\n",
            "Epoch 19: loss improved from 2.98077 to 2.96541, saving model to weights-improvement-19-2.9654.hdf5\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 2.9654\n",
            "Epoch 20/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9516\n",
            "Epoch 20: loss improved from 2.96541 to 2.95160, saving model to weights-improvement-20-2.9516.hdf5\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 2.9516\n",
            "Epoch 21/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9376\n",
            "Epoch 21: loss improved from 2.95160 to 2.93763, saving model to weights-improvement-21-2.9376.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 2.9376\n",
            "Epoch 22/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.9145\n",
            "Epoch 22: loss improved from 2.93763 to 2.91449, saving model to weights-improvement-22-2.9145.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 2.9145\n",
            "Epoch 23/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.8943\n",
            "Epoch 23: loss improved from 2.91449 to 2.89429, saving model to weights-improvement-23-2.8943.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 2.8943\n",
            "Epoch 24/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.8682\n",
            "Epoch 24: loss improved from 2.89429 to 2.86816, saving model to weights-improvement-24-2.8682.hdf5\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 2.8682\n",
            "Epoch 25/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.8396\n",
            "Epoch 25: loss improved from 2.86816 to 2.83955, saving model to weights-improvement-25-2.8396.hdf5\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 2.8396\n",
            "Epoch 26/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.7955\n",
            "Epoch 26: loss improved from 2.83955 to 2.79548, saving model to weights-improvement-26-2.7955.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.7955\n",
            "Epoch 27/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.7526\n",
            "Epoch 27: loss improved from 2.79548 to 2.75262, saving model to weights-improvement-27-2.7526.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 2.7526\n",
            "Epoch 28/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.7064\n",
            "Epoch 28: loss improved from 2.75262 to 2.70641, saving model to weights-improvement-28-2.7064.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 2.7064\n",
            "Epoch 29/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.6482\n",
            "Epoch 29: loss improved from 2.70641 to 2.64825, saving model to weights-improvement-29-2.6482.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 2.6482\n",
            "Epoch 30/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.5848\n",
            "Epoch 30: loss improved from 2.64825 to 2.58478, saving model to weights-improvement-30-2.5848.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 2.5848\n",
            "Epoch 31/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.5150\n",
            "Epoch 31: loss improved from 2.58478 to 2.51503, saving model to weights-improvement-31-2.5150.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.5150\n",
            "Epoch 32/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.4344\n",
            "Epoch 32: loss improved from 2.51503 to 2.43440, saving model to weights-improvement-32-2.4344.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.4344\n",
            "Epoch 33/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.3348\n",
            "Epoch 33: loss improved from 2.43440 to 2.33478, saving model to weights-improvement-33-2.3348.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 2.3348\n",
            "Epoch 34/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.2382\n",
            "Epoch 34: loss improved from 2.33478 to 2.23820, saving model to weights-improvement-34-2.2382.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.2382\n",
            "Epoch 35/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.1306\n",
            "Epoch 35: loss improved from 2.23820 to 2.13064, saving model to weights-improvement-35-2.1306.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.1306\n",
            "Epoch 36/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.0087\n",
            "Epoch 36: loss improved from 2.13064 to 2.00870, saving model to weights-improvement-36-2.0087.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 2.0087\n",
            "Epoch 37/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.8811\n",
            "Epoch 37: loss improved from 2.00870 to 1.88107, saving model to weights-improvement-37-1.8811.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 1.8811\n",
            "Epoch 38/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.7477\n",
            "Epoch 38: loss improved from 1.88107 to 1.74766, saving model to weights-improvement-38-1.7477.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 1.7477\n",
            "Epoch 39/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.6175\n",
            "Epoch 39: loss improved from 1.74766 to 1.61748, saving model to weights-improvement-39-1.6175.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 1.6175\n",
            "Epoch 40/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.4906\n",
            "Epoch 40: loss improved from 1.61748 to 1.49060, saving model to weights-improvement-40-1.4906.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 1.4906\n",
            "Epoch 41/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.3569\n",
            "Epoch 41: loss improved from 1.49060 to 1.35687, saving model to weights-improvement-41-1.3569.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 1.3569\n",
            "Epoch 42/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.2136\n",
            "Epoch 42: loss improved from 1.35687 to 1.21360, saving model to weights-improvement-42-1.2136.hdf5\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 1.2136\n",
            "Epoch 43/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.0879\n",
            "Epoch 43: loss improved from 1.21360 to 1.08794, saving model to weights-improvement-43-1.0879.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 1.0879\n",
            "Epoch 44/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.9709\n",
            "Epoch 44: loss improved from 1.08794 to 0.97090, saving model to weights-improvement-44-0.9709.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.9709\n",
            "Epoch 45/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.8674\n",
            "Epoch 45: loss improved from 0.97090 to 0.86743, saving model to weights-improvement-45-0.8674.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.8674\n",
            "Epoch 46/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.7566\n",
            "Epoch 46: loss improved from 0.86743 to 0.75664, saving model to weights-improvement-46-0.7566.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.7566\n",
            "Epoch 47/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.6671\n",
            "Epoch 47: loss improved from 0.75664 to 0.66713, saving model to weights-improvement-47-0.6671.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.6671\n",
            "Epoch 48/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.5896\n",
            "Epoch 48: loss improved from 0.66713 to 0.58957, saving model to weights-improvement-48-0.5896.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 0.5896\n",
            "Epoch 49/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.5057\n",
            "Epoch 49: loss improved from 0.58957 to 0.50570, saving model to weights-improvement-49-0.5057.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.5057\n",
            "Epoch 50/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.4394\n",
            "Epoch 50: loss improved from 0.50570 to 0.43944, saving model to weights-improvement-50-0.4394.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 0.4394\n",
            "Epoch 51/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.3852\n",
            "Epoch 51: loss improved from 0.43944 to 0.38517, saving model to weights-improvement-51-0.3852.hdf5\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.3852\n",
            "Epoch 52/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.3406\n",
            "Epoch 52: loss improved from 0.38517 to 0.34057, saving model to weights-improvement-52-0.3406.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 0.3406\n",
            "Epoch 53/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.2986\n",
            "Epoch 53: loss improved from 0.34057 to 0.29860, saving model to weights-improvement-53-0.2986.hdf5\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 0.2986\n",
            "Epoch 54/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.2608\n",
            "Epoch 54: loss improved from 0.29860 to 0.26077, saving model to weights-improvement-54-0.2608.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 0.2608\n",
            "Epoch 55/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.2266\n",
            "Epoch 55: loss improved from 0.26077 to 0.22663, saving model to weights-improvement-55-0.2266.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.2266\n",
            "Epoch 56/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1918\n",
            "Epoch 56: loss improved from 0.22663 to 0.19178, saving model to weights-improvement-56-0.1918.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 0.1918\n",
            "Epoch 57/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1714\n",
            "Epoch 57: loss improved from 0.19178 to 0.17141, saving model to weights-improvement-57-0.1714.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 0.1714\n",
            "Epoch 58/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1706\n",
            "Epoch 58: loss improved from 0.17141 to 0.17055, saving model to weights-improvement-58-0.1706.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.1706\n",
            "Epoch 59/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1456\n",
            "Epoch 59: loss improved from 0.17055 to 0.14563, saving model to weights-improvement-59-0.1456.hdf5\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.1456\n",
            "Epoch 60/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1259\n",
            "Epoch 60: loss improved from 0.14563 to 0.12590, saving model to weights-improvement-60-0.1259.hdf5\n",
            "79/79 [==============================] - 46s 587ms/step - loss: 0.1259\n",
            "Epoch 61/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1150\n",
            "Epoch 61: loss improved from 0.12590 to 0.11501, saving model to weights-improvement-61-0.1150.hdf5\n",
            "79/79 [==============================] - 46s 586ms/step - loss: 0.1150\n",
            "Epoch 62/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1217\n",
            "Epoch 62: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 585ms/step - loss: 0.1217\n",
            "Epoch 63/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1191\n",
            "Epoch 63: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 588ms/step - loss: 0.1191\n",
            "Epoch 64/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 2.2402\n",
            "Epoch 64: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 584ms/step - loss: 2.2402\n",
            "Epoch 65/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.9894\n",
            "Epoch 65: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 3.9894\n",
            "Epoch 66/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.8260\n",
            "Epoch 66: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 580ms/step - loss: 3.8260\n",
            "Epoch 67/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.7616\n",
            "Epoch 67: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 3.7616\n",
            "Epoch 68/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.6620\n",
            "Epoch 68: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 3.6620\n",
            "Epoch 69/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.6042\n",
            "Epoch 69: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 3.6042\n",
            "Epoch 70/70\n",
            "79/79 [==============================] - ETA: 0s - loss: 3.5407\n",
            "Epoch 70: loss did not improve from 0.11501\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 3.5407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49edb9bdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-61-0.1150.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "vNwmIqt_KuoT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "REJh6fSPQKgp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "sFwFSmozQoDX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Read:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts-z6wLcQPTz",
        "outputId": "0f6f229a-f524-4986-ba3c-bf11a8a8c791"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read:\n",
            "\" ом, чтобы уметь подняться каждый раз,\n",
            "когда падаешь…\n",
            "видеть то, осуществление чего требует долг, и не сделать — есть отсутствие мужества.\n",
            "владеть собой настолько, чтоб уважать других, как самого себя, и поступать с ними так, как мы желаем,\n",
            "чтобы с нами поступали, — вот что можно назвать учением о человеколюбии.\n",
            "во всем есть красота, но не каждый ее видит.\n",
            "воистину, на свете есть и травы, не дающие цветов, и цветы, не дающие плодов!\n",
            "вот моё главное желание: старые должны жить в покое, друзья должны быть правдивыми, младшие\n",
            "должны проявлять заботу о старших.\n",
            "всё не то, чем кажется и не наоборот.\n",
            "выбери себе работу по душе, и тебе не придётся работать ни одного дня в своей жизни.\n",
            "да не ослепляет тебя ни дружба насчет недостатков твоего друга, ни ненависть насчет хороших качеств\n",
            "твоего врага.\n",
            "давай наставления только тому, кто ищет знаний, обнаружив свое невежество. оказывай помощь только\n",
            "тому, кто не умеет внятно высказать свои заветные думы. обучай только того, кто способен, узнав про\n",
            "од \"\n",
            "ин угол квадрата, представить себе остальные три.\n",
            "даже в обществе двух человек я непременно найду, чему у них поучиться. достоинствам их я постараюсь\n",
            "подражать, а на их недостатках сам буду учиться.\n",
            "добродетель мудрецов напоминает собой путешествие в дальнюю страну и восхождение на вершину:\n",
            "идущие в дальнюю страну начинают свой путь с первого шага; восходящие на вершину начинают с\n",
            "подножия горы.\n",
            "добродетель не останется в одиночестве. у нее обязательно найдутся соседи.\n",
            "достаточно, чтобы слова выражали смысл.\n",
            "достойный человек не идет по следам других людей. оценивая мирские дела, благородный муж ничего не\n",
            "отвергает и не одобряет, а все меряет справедливостью.\n",
            "достойный человек не может не обладать широтой познаний и твердостью духа. его ноша тяжела, а путь\n",
            "его долог. человечность — вот ноша, которую несет он: разве не тожела тна? только смарть  а кегаз ладрчь тааа\n",
            "\n",
            "о з мом уетееть в нюяь — это увтам ость вововот.\n",
            "\n",
            "оаселот  ото ни поееш вотьси всскалать свои заветные думы. обучай только\n",
            "Done.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}